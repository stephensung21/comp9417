{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----bnb\n",
      "[0]\n",
      "[1]\n",
      "[0 1] [0 1]\n",
      "[[0.7850958  0.2149042 ]\n",
      " [0.04828923 0.95171077]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "----mnb\n",
      "[0]\n",
      "[1]\n",
      "[0 1] [0 1]\n",
      "[[0.66666667 0.33333333]\n",
      " [0.05263158 0.94736842]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from https://chrisalbon.com/machine_learning/naive_bayes/multinomial_naive_bayes_classifier/\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Brazil is best',\n",
    "                      'I like Germany more, Germany beats both',\n",
    "                      'I like Italy, because Italy is beautiful',\n",
    "                      'I am from Germany, so I like Germany more'])\n",
    "\n",
    "\n",
    "# Create bag of words\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# Create feature matrix\n",
    "X = bag_of_words\n",
    "\n",
    "# Create target vector\n",
    "y = np.array([0,0,1,0,1])\n",
    "\n",
    "X_train = X[:3]\n",
    "X_test = X[3:]\n",
    "y_train = y[:3]\n",
    "y_test = y[3:]\n",
    "\n",
    "# Create new unseen test instances\n",
    "test1 = count.transform(['I like Italy, because Italy is beautiful'])\n",
    "test2 = count.transform(['I am from Germany, so I like Germany more'])\n",
    "\n",
    "print(\"----bnb\")\n",
    "clf = BernoulliNB()\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "print(model.predict(test1))\n",
    "print(model.predict(test2))\n",
    "predicted_y = model.predict(X_test)\n",
    "print(y_test, predicted_y)\n",
    "print(model.predict_proba(X_test))\n",
    "print(accuracy_score(y_test, predicted_y))\n",
    "print(precision_score(y_test, predicted_y))\n",
    "print(recall_score(y_test, predicted_y))\n",
    "print(f1_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='macro'))\n",
    "print(classification_report(y_test, predicted_y))\n",
    "\n",
    "# Train model\n",
    "print(\"----mnb\")\n",
    "clf = MultinomialNB()\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "print(model.predict(test1))\n",
    "print(model.predict(test2))\n",
    "predicted_y = model.predict(X_test)\n",
    "print(y_test, predicted_y)\n",
    "print(model.predict_proba(X_test))\n",
    "print(accuracy_score(y_test, predicted_y))\n",
    "print(precision_score(y_test, predicted_y))\n",
    "print(recall_score(y_test, predicted_y))\n",
    "print(f1_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='macro'))\n",
    "print(classification_report(y_test, predicted_y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
